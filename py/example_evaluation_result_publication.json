{
    "validator": "Did:ridValidator:0x6FCB287c943C1119c550F350B07e7B4c9f02677C:mit.edu",
    "provider": "Did:ridProvider:Grok3:0x6FCB287c943C1119c550F350B07e7B4c9f02677C:api.x.ai",
    "evaluation": "did:rideval:MTRobustBLUE:dasdasdasdasdasdasdasdasdasda:github.com/robust/MTbench/spec",
    "metrics": [
        {
            "metric_name": "average_BLUE",
            "metric_type": "float",
            "metric_value": 94.1
        },
        {
            "metric_name": "ROC",
            "metric_type": "float",
            "metric_value": 94.1
        },
        {
            "metric_name": "GRE",
            "metric_type": "float",
            "metric_value": 91.1
        },
        {
            "metric_name": "averageRoundReponseTIme",
            "metric_type": "int_ms",
            "metric_value": 302
        }
    ],
    "timestamp_start_eval": 1742145905,
    "timestamp_end_eval": 1742149905,
    "number_of_prompts_behind_score": 100,
    "private_test_data": false,
    "public_test_data": true,
    "test_data_publicized_within": "6months"
}
