functional componenets 

- Functions that help a validator publish ai model benchmark results. Results as aggregate statistics 
- Functions that help ai researchers and validators publish new test data creation standards and evaluation methods. 
- Function to help AI model providers announce that they want to get benchmarked with fresh data on new test data evaluation streams  
- Validator registration simply to connect their public key to an organizations  email or domain. 
- SDK framework that makes it easy for different AI model providers to add a plugin for their specific API to a generic model type function. For instance a machine tanslation SDK  function will have many adapters for different AI model providers with their different API endpoints and authentication types.  [ Similar to   litellm   https://github.com/BerriAI/litellm
]


Things that can be done in a second step 
- Open data publication of all the test data that was used and what answers different models gave 